import streamlit as st
import requests
from bs4 import BeautifulSoup
import pandas as pd
from datetime import date
import time

# --- Streamlit UI ---
st.title("ğŸ” LLMOãƒã‚§ãƒƒã‚¯ãƒ„ãƒ¼ãƒ« v0.1")
st.markdown("æŒ‡å®šã—ãŸãƒ‰ãƒ¡ã‚¤ãƒ³ãŒå„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§Googleæ¤œç´¢çµæœã®ä¸Šä½ã«å‡ºã¦ãã‚‹ã‹ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¾ã™ã€‚")

# å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ 
domain = st.text_input("èª¿æŸ»å¯¾è±¡ãƒ‰ãƒ¡ã‚¤ãƒ³ï¼ˆä¾‹: xxxxx.co.jpï¼‰", "")
keywords_input = st.text_area("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ä¸€è¦§ï¼ˆ1è¡Œã«1ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã€æœ€å¤§10ä»¶ï¼‰", "")

if st.button("åˆ†æã‚¹ã‚¿ãƒ¼ãƒˆ") and domain and keywords_input:
    keywords = [k.strip() for k in keywords_input.strip().split("\n") if k.strip()][:10]
    result_data = []

    headers = {"User-Agent": "Mozilla/5.0"}

    for kw in keywords:
        query = kw.replace(" ", "+")
        url = f"https://www.google.com/search?q={query}"
        response = requests.get(url, headers=headers)
        soup = BeautifulSoup(response.text, "html.parser")
        results = soup.select("div.g")

        found = False
        match_url = ""
        snippet = ""

        for r in results[:5]:
            link_tag = r.find("a")
            if link_tag and link_tag.has_attr("href"):
                link = link_tag["href"]
                text = r.get_text()
                if domain in link or domain in text:
                    found = True
                    match_url = link
                    snippet = text[:150]
                    break

        result_data.append({
            "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰": kw,
            "ãƒ’ãƒƒãƒˆ": "â—‹" if found else "Ã—",
            "URL": match_url,
            "æŠœç²‹": snippet
        })

        time.sleep(1.5)  # Googleã¸ã®è² è·ã‚’é¿ã‘ã‚‹ãŸã‚å°‘ã—å¾…æ©Ÿ

    df = pd.DataFrame(result_data)
    st.success(f"æ¤œç´¢å®Œäº†ï¼{len(df)} ä»¶ä¸­ {df['ãƒ’ãƒƒãƒˆ'].tolist().count('â—‹')} ä»¶ãƒ’ãƒƒãƒˆã—ã¾ã—ãŸã€‚")
    st.dataframe(df)

    # ãƒ’ãƒƒãƒˆç‡ã®é›†è¨ˆ
    hit_rate = df["ãƒ’ãƒƒãƒˆ"].tolist().count("â—‹") / len(df) * 100
    st.metric("ãƒ’ãƒƒãƒˆç‡", f"{hit_rate:.1f}%")

    # CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    csv = df.to_csv(index=False).encode("utf-8")
    st.download_button("CSVã¨ã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=csv, file_name=f"llmo_results_{date.today()}.csv", mime="text/csv")
else:
    st.info("ãƒ‰ãƒ¡ã‚¤ãƒ³ã¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ã€åˆ†æã‚¹ã‚¿ãƒ¼ãƒˆã€ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")
