import streamlit as st
import requests
from bs4 import BeautifulSoup
import pandas as pd
from datetime import date
import time

# --- Streamlit UI ---
st.set_page_config(page_title="LLMOãƒã‚§ãƒƒã‚¯ Lightç‰ˆ", layout="wide")
st.title("ğŸ” LLMOãƒã‚§ãƒƒã‚¯ãƒ„ãƒ¼ãƒ« Lightç‰ˆ (ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å¯¾å¿œ)")
st.markdown("Googleæ¤œç´¢ã‚’è»½é‡æ–¹å¼ï¼ˆrequests + BeautifulSoupï¼‰ã§èª¿æŸ»ã—ã¾ã™ã€‚Streamlit Cloudå¯¾å¿œã€‚")

# å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ 
with st.form("llmo_light_form"):
    domain = st.text_input("èª¿æŸ»å¯¾è±¡ãƒ‰ãƒ¡ã‚¤ãƒ³ï¼ˆä¾‹: yahoo.co.jpï¼‰", "")
    keywords_input = st.text_area("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ä¸€è¦§ï¼ˆ1è¡Œã«1ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã€æœ€å¤§10ä»¶ï¼‰", "")
    enable_debug = st.checkbox("ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ï¼ˆè§£æä¸­ã®URLã‚’è¡¨ç¤ºï¼‰", value=False)
    submitted = st.form_submit_button("åˆ†æã‚¹ã‚¿ãƒ¼ãƒˆ")

# --- å‡¦ç† ---
if submitted and domain and keywords_input:
    keywords = [k.strip() for k in keywords_input.strip().split("\n") if k.strip()][:10]
    result_data = []

    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    }

    for kw in keywords:
        query = kw.replace(" ", "+")
        url = f"https://www.google.co.jp/search?q={query}&hl=ja"
        response = requests.get(url, headers=headers)
        soup = BeautifulSoup(response.text, "html.parser")
        results = soup.select("div.tF2Cxc, div.g, div.MjjYud")

        found = False
        match_url = ""
        snippet = ""
        debug_urls = []

        for r in results[:5]:
            link_tag = r.find("a", href=True)
            if link_tag:
                link = link_tag["href"]
                text = r.get_text()
                debug_urls.append(link)
                if domain.lower() in link.lower() or f"www.{domain}".lower() in link.lower() or domain.lower() in text.lower():
                    found = True
                    match_url = link
                    snippet = text[:150]
                    break

        result_data.append({
            "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰": kw,
            "ãƒ’ãƒƒãƒˆ": "â—‹" if found else "Ã—",
            "URL": match_url,
            "æŠœç²‹": snippet,
            "ãƒ‡ãƒãƒƒã‚°URLä¸€è¦§": "; ".join(debug_urls) if enable_debug else ""
        })

        time.sleep(1.5)

    df = pd.DataFrame(result_data)
    st.success(f"æ¤œç´¢å®Œäº†ï¼{len(df)} ä»¶ä¸­ {df['ãƒ’ãƒƒãƒˆ'].tolist().count('â—‹')} ä»¶ãƒ’ãƒƒãƒˆã—ã¾ã—ãŸã€‚")
    st.dataframe(df)

    hit_rate = df["ãƒ’ãƒƒãƒˆ"].tolist().count("â—‹") / len(df) * 100
    st.metric("ãƒ’ãƒƒãƒˆç‡", f"{hit_rate:.1f}%")

    csv = df.to_csv(index=False).encode("utf-8")
    st.download_button("CSVã¨ã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=csv, file_name=f"llmo_light_results_{date.today()}.csv", mime="text/csv")

else:
    st.info("ãƒ‰ãƒ¡ã‚¤ãƒ³ã¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ã€åˆ†æã‚¹ã‚¿ãƒ¼ãƒˆã€ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚æœ€å¤§10ä»¶ã¾ã§å¯¾å¿œã€‚")
